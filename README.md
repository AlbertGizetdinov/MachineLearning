# Machine Learning
### k-means
Написать с нуля алгоритм k-means без использования библиотек 
(но можно пользоваться библиотеками, не связанными с самим алгоритмом - отрисовки, подсчетов и т.д.) 

Пошагово:
1. Найти оптимальное количество кластеров по формулам. И только для этого оптимального значения выводить рисунки.
2. Рисунки выводятся на каждый шаг – сдвиг центроидов. Сколько шагов, столько рисунков (можно в виде gif). Точки из разных кластеров разными цветами.
3. Точки задаются случайным образом на плоскости. 
4. Центроиды образуют правильную вписанную в окружность фигуру.
5.  Каждый шаг алгоритма – вывод графическми (см. п.2).

### dbscan
1. Начальные объекты - точки, которые не берутся случайно, не берутся из библиотек. Эти точки рисуем сами - мышкой на экране (реализовать можно при помощи библиотеки pygame, например). 
2. Выдавать точкам "флажки" при нажатии на какую-то из кнопок (например, enter). "Флажки" трех типов: зеленые, желтые или красные. Цвета выдавать согласно алгоритму. 
3. На экране, где рисовались точки после выдачи флажков перекрасить их в соответствующие цвета (зеленые, желтые или красные). 
4. Прогнать точки через алгоритм и понять какая лежит в каком кластере. 
5. В зависимости от кластера красить их в цвета - точки из одго кластера одного цвета, точки из разных кластеров разных цветов.
По итогу картинок три основных: просто точки одного цвета, точки одного из трех цветов (зеленые/желтые/красные), точки цветов в зависимости от кластера.

### KNP
1. Случайным образом заполнить матрицу весов в будущем графе (граф не полный, но связный, неориентированный). 
2. Вывести граф целиком в виде рисунка, вывод можно осуществить при помощи какой-либо из библиотек, например networkx. 
3. Найти минимальное остовное дерево (код написать самим) и вывести его в виде рисунка. 
4. Разбить на кластеры и вывести итоговое множество (либо вывести список: номер кластера - точки, или окрасить точки из одного кластера в один цвет, из разных - в разные.

### kNN
1. Датасет – ирис (либо скачать с сайта kaggle, либо вытащить с библиотек sklearn (именно само множество)).
2. Нормализовать данные (самостоятельно). Разделить выборку на две части: обучающую и тестовую. При помощи этого разделения подобрать оптимальное количество соседей k (самостоятельно).
3. Вывести проекции на оси (6 разных картинок, минимум) – причем как до нормализации, так и после (по итогу, минимум 12 картинок).
4. Задавать новый объект (с клавиатуры, файла, нажатием на экран или где-то в коде) и определять его класс – нахождением k его ближайших соседей.

### SVM
1. Выборка - двухклассовая. Задавать случайным образом или отрисовывать мышкой (например, при нажатии на левую - появляются красные точки, при нажатии на правую - синие). Необязательно линейно разделимый случай.
2. Готовым алгоритмом найти прямую, которая бы разделяла наши множества на классы. Вывести данную прямую.
3. Добавить новую точку (для случая pygame – нажатием на среднюю кнопку мыши, для matplotlib – где-то в коде, либо другим каким-то образом). Определить новую точку в нужный класс и окрасить ее в соответствующий цвет.


